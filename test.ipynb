{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tej-prash/Job-Recommendation-System\n",
    "\n",
    "\n",
    "https://github.com/611noorsaeed/Job-Recommendation-System-Machine-Learning/tree/main\n",
    "\n",
    "https://medium.com/@khang.pham.exxact/text-classification-with-bert-7afaacc5e49b#:~:text=How%20does%20the%20BERT%20model,the%20meaning%20of%20the%20text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cleaning\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Similiraty \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Save models\n",
    "import pickle \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\axeld\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\axeld\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\axeld\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please download it once\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_job = pd.read_csv('data\\dice_com-job_us_sample.csv')\n",
    "len(data_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Recommendation by search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When conducting a job search, it is crucial to provide job recommendations that precisely match the user's specific criteria. For this purpose, the recommendation function takes into consideration various aspects:\n",
    "\n",
    "- **Same Title**: Similarity is assessed using vectorization and frequency analysis of the job title.\n",
    "\n",
    "- **Same Description**: Comparison is performed using vectorization and frequency analysis of the job description.\n",
    "\n",
    "- *(**Same Skills**: Relevance of required skills is evaluated through vectorization and frequency analysis of mentioned skills.)*\n",
    "\n",
    "- **Same Company**: A bonus is awarded to jobs from the same company as the initial search.\n",
    "\n",
    "- **Same Employment Status**: An additional bonus is granted to jobs sharing the same employment status as specified in the search.\n",
    "\n",
    "- **Same Location**: A filtering function may be applied to return only jobs located in the same geographical region as the search.\n",
    "\n",
    "- **Recently Posted**: The function can also filter results based on the recency of job postings, providing suggestions that align with freshness criteria.\n",
    "\n",
    "This multi-criteria approach ensures that recommendations align comprehensively with the user's preferences, considering various factors such as semantic similarity, company affiliation, employment status, location, and posting recency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_job = data_job[['company', 'employmenttype_jobstatus', 'jobdescription', \n",
    "                     'joblocation_address', 'jobtitle', 'postdate', 'shift', 'skills']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_job.dropna(inplace=True)\n",
    "data_job.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the WordNet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def txt_cleaning(text):\n",
    "    \"\"\"\n",
    "    Clean a given text, typically used for job descriptions and titles.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The input text to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "    str: The cleaned and processed text.\n",
    "\n",
    "    Steps:\n",
    "    1. Keep only alpha-numeric characters.\n",
    "    2. Tokenize the text for better processing.\n",
    "    3. Apply lemmatization to reduce words to their base form.\n",
    "    4. Remove common English stop words.\n",
    "    \"\"\"\n",
    "    # Keep only alpha-numeric characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "\n",
    "    # Tokenize for better processing\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Apply lemmatization and remove stop words using list comprehension\n",
    "    lemmatization = [lemmatizer.lemmatize(w) for w in tokens if w not in stopwords.words('english')]\n",
    "\n",
    "    return \" \".join(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning jobtitle\n",
      "Cleaning jobdescription\n"
     ]
    }
   ],
   "source": [
    "# 20 min to run !!!\n",
    "print('Cleaning jobtitle')\n",
    "data_job['jobtitle'] = data_job['jobtitle'].apply(lambda x: txt_cleaning(x))\n",
    "\n",
    "print('Cleaning jobdescription')\n",
    "data_job['jobdescription'] = data_job['jobdescription'].apply(lambda x: txt_cleaning(x))\n",
    "\n",
    "def convert_date(date):\n",
    "    # Remove ' ago' from the date\n",
    "    date = date.replace(' ago', '')\n",
    "\n",
    "    # If date is like 'moments ago'\n",
    "    if len(date.split()) == 1:\n",
    "        return datetime.now()\n",
    "\n",
    "    # If date is like '7 minutes ago'\n",
    "    if date.split(' ')[1] in ['minute', 'minutes']:\n",
    "        minutes_ago = int(date.split(' ')[0])\n",
    "        return datetime.now() - timedelta(minutes=minutes_ago)\n",
    "\n",
    "    # If date is like '2 hours ago'\n",
    "    if date.split(' ')[1] in ['hour', 'hours']:\n",
    "        hours_ago = int(date.split(' ')[0])\n",
    "        return datetime.now() - timedelta(hours=hours_ago)\n",
    "\n",
    "    # If date is like '2 weeks ago'\n",
    "    if date.split(' ')[1] in ['week', 'weeks']:\n",
    "        weeks_ago = int(date.split(' ')[0])\n",
    "        return datetime.now() - timedelta(weeks=weeks_ago)\n",
    "\n",
    "    # If date is like '1 month ago'\n",
    "    if date.split(' ')[1] in ['month', 'months']:\n",
    "        months_ago = int(date.split(' ')[0])\n",
    "        return datetime.now() - timedelta(days=30 * months_ago)\n",
    "\n",
    "data_job['postdate'] = data_job['postdate'].apply(lambda x: convert_date(x))\n",
    "\n",
    "data_job['skills'].fillna('', inplace=True)\n",
    "data_job['skills'] = data_job['skills'].apply(lambda x: txt_cleaning(x))\n",
    "data_job['requirements'] = data_job['jobtitle'].apply(lambda x: x.lower()) + ' ' + data_job['jobdescription'].apply(lambda x: x.lower()) + ' ' + data_job['skills'].apply(lambda x: x.lower())\n",
    "\n",
    "data_job.head()\n",
    "data_job.to_csv('data\\data_job_clean.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>employmenttype_jobstatus</th>\n",
       "      <th>jobdescription</th>\n",
       "      <th>joblocation_address</th>\n",
       "      <th>jobtitle</th>\n",
       "      <th>postdate</th>\n",
       "      <th>shift</th>\n",
       "      <th>skills</th>\n",
       "      <th>requirements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Digital Intelligence Systems, LLC</td>\n",
       "      <td>C2H Corp-To-Corp, C2H Independent, C2H W2, 3 M...</td>\n",
       "      <td>looking selenium engineer must solid java codi...</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>automation test engineer</td>\n",
       "      <td>2024-01-15 11:16:01.533834</td>\n",
       "      <td>Telecommuting not available|Travel not required</td>\n",
       "      <td>see</td>\n",
       "      <td>automation test engineer looking selenium engi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University of Chicago/IT Services</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>university chicago rapidly growing security pr...</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>information security engineer</td>\n",
       "      <td>2024-01-08 12:16:01.533834</td>\n",
       "      <td>Telecommuting not available|Travel not required</td>\n",
       "      <td>linux unix network monitoring incident respons...</td>\n",
       "      <td>information security engineer university chica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Galaxy Systems, Inc.</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>galaxe solutionsevery day solution affect peop...</td>\n",
       "      <td>Schaumburg, IL</td>\n",
       "      <td>business solution architect</td>\n",
       "      <td>2024-01-01 12:16:01.533834</td>\n",
       "      <td>Telecommuting not available|Travel not required</td>\n",
       "      <td>enterprise solution architecture business inte...</td>\n",
       "      <td>business solution architect galaxe solutionsev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TransTech LLC</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>java developerfull time direct hirebolingbrook...</td>\n",
       "      <td>Bolingbrook, IL</td>\n",
       "      <td>java developer mid level ft great culture mode...</td>\n",
       "      <td>2024-01-01 12:16:01.533834</td>\n",
       "      <td>Telecommuting not available|Travel not required</td>\n",
       "      <td>please see job description</td>\n",
       "      <td>java developer mid level ft great culture mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matrix Resources</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>midtown based high tech firm immediate need in...</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>devops engineer</td>\n",
       "      <td>2024-01-15 11:28:01.533834</td>\n",
       "      <td>Telecommuting not available|Travel not required</td>\n",
       "      <td>configuration management developer linux manag...</td>\n",
       "      <td>devops engineer midtown based high tech firm i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             company  \\\n",
       "0  Digital Intelligence Systems, LLC   \n",
       "1  University of Chicago/IT Services   \n",
       "2               Galaxy Systems, Inc.   \n",
       "3                      TransTech LLC   \n",
       "4                   Matrix Resources   \n",
       "\n",
       "                            employmenttype_jobstatus  \\\n",
       "0  C2H Corp-To-Corp, C2H Independent, C2H W2, 3 M...   \n",
       "1                                          Full Time   \n",
       "2                                          Full Time   \n",
       "3                                          Full Time   \n",
       "4                                          Full Time   \n",
       "\n",
       "                                      jobdescription joblocation_address  \\\n",
       "0  looking selenium engineer must solid java codi...         Atlanta, GA   \n",
       "1  university chicago rapidly growing security pr...         Chicago, IL   \n",
       "2  galaxe solutionsevery day solution affect peop...      Schaumburg, IL   \n",
       "3  java developerfull time direct hirebolingbrook...     Bolingbrook, IL   \n",
       "4  midtown based high tech firm immediate need in...         Atlanta, GA   \n",
       "\n",
       "                                            jobtitle  \\\n",
       "0                           automation test engineer   \n",
       "1                      information security engineer   \n",
       "2                        business solution architect   \n",
       "3  java developer mid level ft great culture mode...   \n",
       "4                                    devops engineer   \n",
       "\n",
       "                    postdate                                            shift  \\\n",
       "0 2024-01-15 11:16:01.533834  Telecommuting not available|Travel not required   \n",
       "1 2024-01-08 12:16:01.533834  Telecommuting not available|Travel not required   \n",
       "2 2024-01-01 12:16:01.533834  Telecommuting not available|Travel not required   \n",
       "3 2024-01-01 12:16:01.533834  Telecommuting not available|Travel not required   \n",
       "4 2024-01-15 11:28:01.533834  Telecommuting not available|Travel not required   \n",
       "\n",
       "                                              skills  \\\n",
       "0                                                see   \n",
       "1  linux unix network monitoring incident respons...   \n",
       "2  enterprise solution architecture business inte...   \n",
       "3                         please see job description   \n",
       "4  configuration management developer linux manag...   \n",
       "\n",
       "                                        requirements  \n",
       "0  automation test engineer looking selenium engi...  \n",
       "1  information security engineer university chica...  \n",
       "2  business solution architect galaxe solutionsev...  \n",
       "3  java developer mid level ft great culture mode...  \n",
       "4  devops engineer midtown based high tech firm i...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_job.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization TF-IDF\n",
    "data_job = pd.read_csv('data/data_job_clean.csv')\n",
    "data_job = data_job[:len(data_job) // 8]\n",
    "data_job['postdate'] = pd.to_datetime(data_job['postdate'])\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "matrix_title = vectorizer.fit_transform(data_job['jobtitle'])\n",
    "matrix_description = vectorizer.fit_transform(data_job['jobdescription'])\n",
    "\n",
    "# Similarity calculus\n",
    "similarities_title = cosine_similarity(matrix_title)\n",
    "similarities_description = cosine_similarity(matrix_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the models in a file \n",
    "# with open('models\\similarties_title.pkl', 'wb') as file:\n",
    "#     pickle.dump(similarities_title, file)\n",
    "\n",
    "# with open('models\\similarities_description.pkl', 'wb') as file:\n",
    "#     pickle.dump(similarities_description, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_keywords(main_string, keywords):\n",
    "    main_list = main_string.split(' ')\n",
    "    keywords_list = keywords.split(' ')\n",
    "    return all(keyword in main_list for keyword in keywords_list)\n",
    "\n",
    "def find_best_search_indx(expression, data_job, top_n=50):\n",
    "    expression = expression.lower()\n",
    "    meilleurs_scores = [0] * top_n\n",
    "    meilleurs_indices = [None] * top_n\n",
    "\n",
    "    for index, job_title in enumerate(data_job['jobtitle']):\n",
    "        job_title_lower = job_title.lower()\n",
    "        score = SequenceMatcher(None, expression, job_title_lower).ratio()\n",
    "\n",
    "        for i, top_score in enumerate(meilleurs_scores):\n",
    "            if score > top_score:\n",
    "                meilleurs_scores[i] = score\n",
    "                meilleurs_indices[i] = index\n",
    "                break\n",
    "\n",
    "    return [index for index in meilleurs_indices if index is not None]\n",
    "\n",
    "def search(input_text, **kwargs):\n",
    "    \"\"\"\n",
    "    Search for a job in the dataset based on the input text and optional filters.\n",
    "\n",
    "    Parameters:\n",
    "    - input_text (str): Text entered by the user.\n",
    "    - **kwargs (dict): Filters for company, employmenttype_jobstatus, and joblocation.\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: The line in the dataset that matches the criteria, or None if no match is found.\n",
    "    \"\"\"\n",
    "    # Security None in kwargs\n",
    "    keys_to_remove = [col for col, value in kwargs.items() if value is None]\n",
    "    for key in keys_to_remove:\n",
    "        del kwargs[key]\n",
    "\n",
    "    if input_text is None:\n",
    "        return [value for _, value in data_job.head(10).T.to_dict().items()]\n",
    "\n",
    "    # Initialize a mask to filter the dataset\n",
    "    mask = (data_job['jobtitle'].apply(lambda x: detect_keywords(x, input_text)) | data_job['jobtitle'].str.contains(input_text, case=False, na=False))\n",
    "\n",
    "    # If the mask is not empty = if the research is exactly found in the dataset\n",
    "    if not mask[mask == True].empty:\n",
    "        # Apply additional filters if provided\n",
    "        if kwargs:\n",
    "            for key, value in kwargs.items():\n",
    "                mask &= (data_job[key] == value)\n",
    "\n",
    "        # Get the matching row from the dataset\n",
    "        result = data_job[mask]\n",
    "\n",
    "        # Return the result (a DataFrame if there are matches, None otherwise)\n",
    "        return [value for _,value in result.T.to_dict().items()] if not result.empty else [value for _, value in data_job.head(10).T.to_dict().items()]\n",
    "    \n",
    "    # else we look through similarity\n",
    "    else:\n",
    "        # Use the function to find the most similar job title\n",
    "        result = find_best_search_indx(input_text, data_job)\n",
    "        temp = data_job.loc[result]\n",
    "\n",
    "        if result:\n",
    "            # Apply additional filters if provided\n",
    "            if kwargs:\n",
    "                for key, value in kwargs.items():\n",
    "                    mask = (data_job[key].apply(lambda x: detect_keywords(x, value)) | data_job[key].str.contains(value, case=False, na=False))\n",
    "                    temp = temp[mask]\n",
    "\n",
    "            # Return the result (a DataFrame if there are matches, None otherwise)\n",
    "            return [value for _, value in temp.T.to_dict().items()] if not temp.empty else [value for _, value in data_job.head(10).T.to_dict().items()]\n",
    "        else:\n",
    "            return [value for _, value in data_job.head(10).T.to_dict().items()]\n",
    "\n",
    "def calculate_recency_bonus(date_published):\n",
    "    current_date = datetime.now()\n",
    "    delta = current_date - date_published\n",
    "    days_ago = delta.days\n",
    "    return max(0, 0.5 - days_ago * 0.02)  # Bonus decreases linearly over time\n",
    "\n",
    "\n",
    "def recommendation_search(searchs, **kwargs):\n",
    "    \"\"\"\n",
    "    Search for job recommendations based on a given search result and optional filters.\n",
    "\n",
    "    Parameters:\n",
    "    - searchs (list): historical searchs from the user\n",
    "    - **kwargs (dict): Optional filters for company, employmenttype_jobstatus, and joblocation.\n",
    "\n",
    "    Returns:\n",
    "    - pd.Series: Job titles that match the search criteria and filters, sorted by relevance. Top 11 as the first one is tu current search\n",
    "\n",
    "    Notes:\n",
    "    - The function calculates a relevance score based on the similarity of the job title and description.\n",
    "    - Top 10 jobs with the highest relevance scores are returned.\n",
    "    - Additional filters can be applied using **kwargs to refine the search.\n",
    "    - A recency bonus is applied to prioritize more recent job postings.\n",
    "\n",
    "    Formula used : score = 0.3 * title_similarity + 0.7 * description_similitary + sum(1 for each filter macthed) + max(0, 0.5 - days_ago * 0.02)\n",
    "\n",
    "    \"\"\"\n",
    "    if searchs is None:\n",
    "        return None\n",
    "    \n",
    "    result = {}\n",
    "    for s in searchs:\n",
    "\n",
    "        search_result = search(s)\n",
    "        \n",
    "        # Find index of the search\n",
    "        search_result = pd.DataFrame(search_result)\n",
    "        search_result = data_job.reset_index().merge(search_result, on=['company', 'jobdescription_old', \n",
    "                                                                    'joblocation_address', 'jobtitle_old', 'postdate',\n",
    "                                                                    'jobtitle', 'jobdescription', 'requirements'], \n",
    "                                                                how='inner')\n",
    "\n",
    "        for indx in search_result['index']:\n",
    "            # Get similarities with this search\n",
    "            score_title = list(enumerate(similarities_title[indx]))\n",
    "            score_description = list(enumerate(similarities_description[indx]))\n",
    "\n",
    "            # Calculate relevance scores for each job\n",
    "            scores = {score_title[i][0]: score_title[i][1] * 0.3 + score_description[i][1] * 0.7 for i in range(len(score_title))}\n",
    "            scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True)[:11])\n",
    "\n",
    "            # Apply additional filters if provided\n",
    "            if len(kwargs) > 0:\n",
    "                for idx, score in scores.items():\n",
    "                    temp = data_job.loc[idx]\n",
    "                    for col, value in kwargs.items():\n",
    "                        if value.lower() in temp[col].lower():\n",
    "                            scores[idx] += 1\n",
    "\n",
    "            # Apply recency bonus\n",
    "            for idx in scores.keys():\n",
    "                recency_bonus = calculate_recency_bonus(data_job.loc[idx]['postdate'])\n",
    "                scores[idx] += recency_bonus\n",
    "            \n",
    "\n",
    "        # Get top 10 jobs based on the combined relevance score and filters\n",
    "        scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True)[:10])\n",
    "        for k,v in scores.items():\n",
    "            if k in result.keys():\n",
    "                result[k] += v\n",
    "            else:\n",
    "                result[k] = v\n",
    "\n",
    "\n",
    "    # Create a DataFrame with job titles, filter values, and scores\n",
    "    res = data_job.loc[result.keys()][['jobtitle', 'jobdescription_old', 'company'] + list(kwargs.keys())]\n",
    "    res['score'] = [result[idx] for idx in result]\n",
    "    res.sort_values('score', ascending=False, inplace=True)\n",
    "    \n",
    "    return [value for _, value in res.head(10).T.to_dict().items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'jobtitle': 'machine learning data scientist qpid boston',\n",
       "  'jobdescription_old': 'Would you like to contribute creatively to a large, meaningful mission? We are in the processing of transforming healthcare. In particular, we are transforming the way that care givers across the country integrate information and make decisions.With the recent combination of QPID Health and eviCore healthcare, we now have an unprecedented combination of scale and industry leading technology and talent to change the way we experience healthcare.Specifically designed with the size and scale to address the complexity of today’s and tomorrow’s healthcare system, we are a company committed to advancing medical benefits management – and enabling better outcomes for patients, providers, and plans.Ours is an evidence-based approach that leverages our exceptional capabilities, powerful analytics, and an acute sensitivity to the challenges and needs of everyone involved across the healthcare spectrum. Applying proven talent and leading-edge technology, we harness healthcare’s evolving demand and inherent change to realize and deliver improved results for everyone.Want to join us? QPID Health, an eviCore company, leverages our deep evidence based knowledge and technology to deliver services and software solutions so healthcare payers and providers can deliver the best quality care. Our natural language processing (NLP) and machine learning (ML) platform replaces outdated manual processes with software-driven clinical reasoning. To see what we’re up to, follow us onTwitter and LinkedIn and visit our website.We are seeking highly creative and motivated post graduate and/or postdoctoral data scientists with exceptional skills who will complement our growing team.QPID’s NLP platform coupled with large proprietary healthcare datasets and strategic vision of transforming decision making in healthcare require a state of the art machine learning platform. As a machine learning data scientist, you will:Design, develop, and prototype machine learning and statistical analysis techniques to automate clinical decision making, including deep learning, collaborative filtering, and other machine learning techniques to extract insights at scale from structured and unstructured electronic health record data and other healthcare data sources.Design and apply statistical techniques to evaluate and monitor the outcomes of automated clinical decision making at scaleHelp evolve QPID’s NLP platform, combining input from clinicians and other domain experts with state of the art NLP techniquesBuild data driven apps whose goals are to: translate data into intelligence, help transform the work of clinical decision making, quality reporting and pathway planning, and to help solve a variety of strategic business problems in healthcare.Assists business with causal inferences & observations providing data-driven business insights. Requirements:“Can do” attitude: you are biased towards action and ready to speak your mindPh.D. in Computer Science, Mathematics, Statistics, Engineering, or a related field, or Master’s degree with 3+ years of industry experience.Strong publication record and/or additional industry experience a plusDeep machine learning expertise. Experience with Deep Learning and/or Natural Language Processing algorithms and tools a strong plus.Experience with a diverse set of computing technologies: Python, Linux, Bash, SQL. High proficiency in Python a strong plus. Experience with Java/C++ a strong plus.Experience with big data frameworks (Hadoop, Spark, etc.) and/or NoSQL databases a plusExperience with healthcare data a plusExcellent organizational and communication skillsWhat’s in it for you, other than improving patient care? We carefully select really smart people and provide them with the autonomy to build great software. We recognize and reward based on merit, not titles. We have amazing views from our offices, lots of food, an espresso machine and other perks. But most of all we offer the chance to build your career with people like you who want to solve problems, and have fun together.',\n",
       "  'company': 'CareCore | MedSolutions',\n",
       "  'score': 1.0000000000000004},\n",
       " {'jobtitle': 'lead sr data scientist',\n",
       "  'jobdescription_old': 'Title: Lead Data Scientist (Applied Researcher)Summary:You will be working as a Data Scientist for one of our clients in San Francisco. You should have a strong background in science and engineering skills, proven track record of solving critical business problems through data science and strong analytical/quantitative and engineering skills. Position Type: Fulltime/ C2HLocation: San Francisco, CARequired Skills: Machine Learning, Data Analytics, Big Data (Spark/Hadoop) What you will be doing?You will be working with our clients team on heterogeneous data sets (behavioral, transaction and crawled data) and focuses on solving applied problems using Natural Language Processing, Text Mining, Data Mining & Machine Learning.Review and guide the daily findings of a team of data scientists.Communicate to the internal data scientists and broader audience about the differences between different analytic techniques for predictions, clustering, and visualizations to make complex data simpler to understand.Dive into the underlying data, apply relevant data mining techniques and/or machine learning algorithms that will help customers get more value from the application.Assist with identification, collection and cleaning of relevant data sources.Understand existing application features and how they tie to our customer’s business needs.Design and support effective storage and retrieval of data in consideration of analytic options.Create and implement algorithms in relevant statistical inference, graph and network analysis, natural language processing with open source tools and libraries.Build prototypes to help visualize different types of data in the most clear way possible.Participate in agile development process, daily scrums, sprint planning, and demos of your work to Engineering peers and leadership.Consult with Product team and other cross-functional teams to assist them with investigation of various data-driven solutions.Keep abreast of cutting-edge solutions for big data analytics and machine learning at scale.What you will need for this role?Degree in Computer Science, Mathematics, Engineering, or equivalent6+ years of professional Data Science experienceProven experience leading talented data scientistsExperience with the following:Mathematical modeling, Statistics, and Machine Learning techniquesMathematical modeling, Statistics, and Machine Learning techniquesStatistical programming languages (e.g. R, Python, Java)Database experience (e.g. MySQL, PostgreSQL)Big data solutions (e.g. Hadoop, Spark)Ability to learn quickly in a fast-paced, dynamic team environmentHighly effective communication and collaboration skills Connect with Us:If you think this post is all about you, ping me at dbind@bayonesolutions.com. I will be happy to answer your questions at 925-307-7147 About Us:We are a business and technology services firm specializing in IT Consulting, Application Development, Systems Integration, Cloud Computing, Data Warehousing and Business Intelligence, and others. Our portfolio of clients includes Fortune 500 and startups. We believing in matching our Consultants talent and core values with that of our clients resulting in ‘Happy’ customers.Thanks, Dhanraj BindRecruiting ManagerBayOne Solutions Pleasanton, CA 94588dbind@bayonesolutionsPh: 925-307-7147',\n",
       "  'company': 'BayOne Solutions',\n",
       "  'score': 0.8096313588708723},\n",
       " {'jobtitle': 'data scientist',\n",
       "  'jobdescription_old': 'Our client, one of the largest financial services firms, is seeking a Data Scientist .   Location : Long Island City, NY Position Type: Contract   - We are searching for a certain kind of person who is excited by the idea of owning; people who like to build new platforms, features and services from scratch and are comfortable managing the ambiguity. - As a member of the Innovation Lab you will have to opportunity to work with a team of highly motivated, T-shaped, smart individuals whose daily job is to think out of the box and look for disruptive opportunities with a commercial benefit. - You will learn about the business and technologies that make the company hum, giving you exposure to new and existing methodologies and systems and the opportunity to work with multiple teams around the globe. - Working within the senior leadership team of the innovation network you will be highly visible across the company . - You will have access to the company’s executive management team and be exposed to newly released and upcoming technologies with the ability to positively contribute to the strategies of the business.   Role responsibilities : - Provide expertise in big data analytics, data mining and regulations surrounding data transport. - Demonstrate high judgment early in the problem analysis phase to assess fit and likelihood of success. - Selecting features, building and optimizing classifiers and predictive models using models, algorithms and approaches appropriate for the problem. - Ability to be effective in all phases for product development from inception to delivery. - Create / contribute to the creation of new innovation project proposals including the socialization with stakeholders, the creation of business cases, cost and revenue projections. - Ability to execute on multiple concurrent initiatives and projects of varying sizes and complexity. - Effective upward and downward communication on all notable progress to all key stakeholders.   Knowledge / Experience : - Master’s Degree in Computer Science, Engineering, Statistics, Math, or related disciplines, with a strong publication record or demonstrable record of delivery. -Self-sufficient with experience in experimental design and early development activities to validate/invalidate ideas. - Capable of analyzing and manipulating data with proficiency in SQL and NoSQL environments. - Solid and proven background and experience with Python, R, C/C++, Java or Scala for large scale data analytics. Not only R or Matlab . - Assesses, with the business, opportunities to enhance the qualification and assurance of the information to strengthen the use case. - At least 2 years’ experience in machine learning at large scale and in production. - At least 2 years’ experience in data analytics, statistical programming, and data mining. - At least 2 years’ experience tackling problems involving Big Data, e.g., using the Apache Spark / Hadoop stack. - Adequate presentation and communication skills to explain results and methodologies to non-technical stakeholders. - Experience in the financial industry and analyzing customer behavioral data is a plus.   Qualifications : - Master’s Degree in Computer Science, Engineering, Statistics, Math, or related disciplines. - A minimum of 5 years’ experience in a similar role (Senior Data Analysis, Data Scientist ….) - Experience working with innovative and emerging technology. - Exceptional candidates who do not meet these criteria may be considered for the role provided they have the necessary skills and experience',\n",
       "  'company': 'Mitchell Martin',\n",
       "  'score': 0.7585475969513169},\n",
       " {'jobtitle': 'senior data scientist',\n",
       "  'jobdescription_old': \"TAD PGS, INC. is currently seeking a Senior Data Scientist for one of our clients in Columbia, MD. Job Overview: The Senior Data Scientist will work both with the Chief Data Scientist and across business teams to leverage broad foundation of technology and data assets to deliver data science solutions to customers. In this role, you will be responsible for leading a team of data scientists and engineers in the delivery of products and custom solutions, from concept to production delivery and maintenance. Primary Responsibilities: Directly lead data science and engineering team members day to day work, including daily scrums and oversight of work product results and qualityParticipate in roadmap development and priority setting for the data science teamWork with varying teams and clients to define business needs and success criteria, and deliver appropriate scalable solutions.Develop algorithmic solutions to various data science focused challenges that utilize very large data setsGenerate visualizations to communicate complex data science topics to business teams and clientsUtilize established open source technologies when available, develop innovative and proprietary solutions when necessary Basic Hiring Criteria: Masters in statistics, computer science or other data rich field of study; or significant relevant industry experience in machine learning and statistics10+ years' experience creating and implementing machine learning algorithms for predictive, inference, classification, and analytical use cases3 + years' experience overseeing a team of data scientists and engineers Preferred Qualifications: Proven ability to self-start and manage competing priorities by engaging with appropriate stakeholdersExpertise utilizing big data technologies, such as Hadoop, MapReduce and Spark, for both ad hoc analysis and product developmentExpertise with scripting and/or programming languages, such as Python, Scala or JavaExperience with cloud services, such as Amazon Web ServicesExperience with querying relational databases using SQLAbility to collaborate with business and engineering teams, both in and outside of the company, with varying levels of data science and technical know howTAD PGS, INC. specializes in delivering secure, reliable and rapidly implemented workforce solutions to the U.S. Federal marketplace, including U.S. Government agencies and their prime contractors. With more than 50 years of experience, TAD PGS, INC. has earned a reputation for accountability, a value that government agencies and prime contractors both demand and deserve.TAD PGS, INC. sources professionals for the full spectrum of federal positions, from administrative to management, and those contracts requiring extremely niche-oriented technical skills and the highest levels of security clearance.\",\n",
       "  'company': 'TAD PGS, Inc',\n",
       "  'score': 0.7475505390223343},\n",
       " {'jobtitle': 'director deep learning data architecture',\n",
       "  'jobdescription_old': 'Director, Deep Learning Data ArchitectureBroadridge Advisor Solutions is the fast-growing Marketing Technology business unit of Broadridge, one of the world\\'s largest and most successful Fin-Tech companies. We\\'re looking for a gifted Data Architect to join our Boston-based product development team, building one of our most ground breaking products yet. A position on this team offers a team oriented startup culture, with the resources and stability of an established player along with the ability to work on new and emerging technologies. You\\'ll will be joining a core team who has one purpose: the development and launch of this new suite of software products and tools that enable our enterprise clients to turn data into insights and client engagement. The development of these solutions is a critical initiative, backed by significant investment and is highly visible across the organization. We are guided by the belief that people are our greatest asset and are committed to attracting the best talent. In this position, you\\'ll be responsible for providing expertise and hands on leadership in the design and development of a modern big data engine that will serve as the backbone for our new deep learning products. This includes sourcing into a data reservoir, managing complex access controls and encryption methodologies, developing ETL processes, integrating modern end-user software, and streamlining data consumption by data scientists, reporting teams and operational applications. We\\'ll rely on your proven track record in data architecture and data management principles as well as artificial intelligence and deep-learning technologies. Specific responsibilities include:* Design and develop highly scalable and optimized data models using modeling software to document and maintain versions to support Data Marts, Cubes, Data Warehouse, and Operational Data Stores (ODS). * Perform source system analysis and meet with business leads to create appropriate requirement definition artifacts. * Serve as a key voice in selection of technologies, equipment, and vendors. * Develop, adapt and map general machine learning algorithms based on requirements of our software * Invent new models that combine unsupervised and supervised learning with the kind of creativity usually reserved during novel computing paradigm creation * Design and develop data quality rules for Data Warehouse and Data Mart solutions to ensure data integrity levels are met. * Research new database and machine learning technologies and recommend solutions in order to meet requirements and long term performance scalability, & storage needs * Develop data standards in terms of nomenclature, storage, design and deployments. * Maintain the end-to-end vision of the data flow diagram and develop logical data models into one or more physical data repositories * Document logical data integration (ETL) strategies for data flows between disparate source/target systems for structured and unstructured data into common data reservoir and the enterprise information repositories * Develop and maintain controls on data quality, interoperability and sources to effectively manage corporate risk * Train, lead, and mentor staff that may include database engineers and DBAs. * Design logical and physical database architecture for DEV, Test, Stage and Prod environments. *DICE_TA *LI-PH1 *TM_01Qualifications:* Deep passion and fundamental understanding of design, algorithms, and data structures in modern and sub-modern machine learning and AI fields * Strong understanding of the fundamentals of neural networks and all common general algorithms * Extensive experience and accomplishment are recommended but are not an absolute requirement. Master\\'s or PhD, or equivalent knowledge in computer science, electrical engineering or related fields (statistics, applied math, computational neuroscience) * 10+ years of hands on experience in Data Management/Data Architecture/Application architecture/Data Development. * Experience in high availability SaaS commercial software products is a must * 5+ years of experience working with modern big data systems for data management, data architecture, security and access controls * Experience managing data transformations using machine learning libraries * Experience selecting and implementing the database components of a brand new technology stack * Wide and extensive expertise in data technologies; i.e., data warehousing, ETL, MDM, DQ, BI and analytical tools. Extensive experience in metadata management and data quality processes * Hands-on experience with dimensional modeling techniques and creation of logical and physical data models (entity relationship modeling, Erwin diagrams, etc.) * Advanced analytical thinking and problem solving skills * Experience designing highly scalable production databases in the cloud (AWS/Azure) is preferred * Experience with a variety of relational databases * Experience with NoSQL databases like DynamoDB, Azure Table Storage, Azure Blog Storage or Amazon S3.* Knowledge of Data Matching, Data Monitoring, Data Enrichment & Data Standardization* Ability to provide in-depth analysis of where gaps in governance and integration capabilities may lie * Some knowledge of current frameworks such as TensorFlow, Caffe, etc. * Driven and self-motivated with an entrepreneurial spirit and a commitment to excellence in everything they do. * Ability to build and maintain positive, multi-year business relationships with peers and customer Broadridge Financial Solutions, Inc. (NYSE:BR) is a global Fin-tech company with a market cap of ~$8B. We are the leading provider of investor communications and technology-driven solutions for broker-dealers, banks, mutual funds and corporate issuers globally. Broadridge\\'s investor communications, securities processing and data and analytics solutions provide financial institutions complex, high performance, scalable platforms to help them grow their businesses... Broadridge employs approximately 10,000 full-time associates globally with a significant presence in North America, Europe and Asia. Please visit our website www.broadridge.com to learn more. Broadridge is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, or any other status protected by law. Click here to view the \"EEO is the Law\" poster.\"Our Associates Matter, Everyone Benefits from Diversity & Inclusion, Diverse & Inclusive Teams Drive Growth\" Feel free to reach us at: broadridgetalent.acquisitionteam@broadridge.com Equal Opportunity Employer Minorities/Women/Protected Veterans/Disabled',\n",
       "  'company': 'Broadridge Financial Solutions, Inc',\n",
       "  'score': 0.7432687663561218},\n",
       " {'jobtitle': 'data scientist',\n",
       "  'jobdescription_old': 'Our client is seeking a Data Scientist.   Location : Bethesda, MD Position Type: Full Time   - Deep understanding of database theory and practice – how do you build a fast database. - Experience with large datasets and big data technologies ( hadoop , map/reduce, NoSQL). - Experience with ETL and the process of turning “data” into “information”. - Business savvy to work with non-technical people to understand the data and what it means. - Experience with reporting technologies',\n",
       "  'company': 'Mitchell Martin',\n",
       "  'score': 0.720441484419853},\n",
       " {'jobtitle': 'data scientist',\n",
       "  'jobdescription_old': 'Looking for an exciting career in Data and Analytics? Scalable Systems is a USA based Big Data, Analytics and Digital Transformation company focused on vertical specific innovative solutions. By providing next generation technology solutions and services, we help organizations to identify risks & opportunities, achieve operational excellence and to gain an innovative edge.Scalable is looking for Data Scientist for one of our esteemed Client at Boston, MA USA.Job Requirements:Support business optimization of marketing, sales and support efforts via data mining, modeling, user segmentation and forecasting.Through Data mining, predictive modeling, customer segmentation and forecasting, data scientist will focus on finding business insights to be consumed by multiple functional teamsAct independently to identify and evangelize opportunities for improved analysis and efficiency through better data and analytics practices.Required Skills:Understanding and knowledge of SAS, SPSS, MatLab, R, STATA, Excel etc.Strong problem solving and analytical skills with the desire to apply those skills in analyzing complex business problemsAbility to communicate complex quantitative analysis and analytic approaches in a clear, precise, and actionable mannerExperience in statistics, data mining, machine learning and predictive modeling is a mustExcellent Data Analytical / User interaction and Presentation SkillsComfort manipulating and analyzing complex, high-volume, high-dimensionality data from varying data sources and big data sources.Expert knowledge of a scientific computing language such as R, Python a plusHands on with various datasets/entities including Campaign, Response, Lead, Contact, Account, Partner, Opportunity, Quote, Order, Asset, Entitlement, Service Request etc.Interested Candidates, request you to please forward your resume to s.mohanty@scalable-systems.com for consideration. Also you can call at 732-659-0961 for any further discussion.Scalable Systems is an Equal Opportunity-Affirmative Action Employer - Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation',\n",
       "  'company': 'Scalable Systems',\n",
       "  'score': 0.6030000395392159},\n",
       " {'jobtitle': 'data scientist waltham',\n",
       "  'jobdescription_old': \"Job Description As a Data Scientist on the Innovation Team, you will be an authoritative subject matter expert on algorithms and techniques to predict and optimize conditions in the network that ultimately extract business value out of the data.  You will be responsible for understanding the Team's big data objectives, how they contribute to 's success, and then investigating and implementing data science technologies that best support the team's mission.  You will analyze cutting-edge technologies and make recommendations to sr executives on the future technologies. As part of the Innovation Team, you will be working in a fast-paced environment focused on rapidly identifying, evaluating, and deploying big data solutions.  You will interact with the data engineers ingesting and storing the data, the AnalyticOps teams who are productizing the new algorithms, the  teams collecting data, vendors, and open source communities to develop a comprehensive understanding of data science techniques and trends so that  big data becomes a competitive advantage in 's mission to deploy the highest-quality, lowest-cost network.  Responsibilities Work with data owners inside, to understand what  network and IT data is available.Work with busines unit stakeholders to understand high-cost areas and use cases that could be impvroved via prediciton and optimizationPerform exploratory data analysis to understand the relationships between data sets and the most valuable data sets.Develop and implement big data, machine learning, and artificial intelligence capabilities that can predict and optimize key quantities and events in the  network.Author and collaborate on Technical Requirements, Specifications, Proposals, High Level Designs, and other applicable engineering documents.Conduct detailed technology research on industry and vendor solutions for analyzing data and implement new solutions in the Innovation Team's lab to identify those which are the most promising.Provide thought leadership for the Data Infrastructure & Analysis team and collaborate with cross-functional engineering teams to streamline or improve adoption of analytics into their projects.Minimum qualification requirements Bachelor's degree in Computer Science, Electrical Engineering, or Computer Engineering preferred.1+ years of experience developing and implementing machine learning and artificial intelligence algorithms.Ability to work in a team and independently on multiple high priority projects. Ability to manage multiple high-visibility, complex technical projects.Extremely strong problem solving skills.Strong written and oral communication skills.Familiarity and practical experience with modern machine learning tools such as TensorFlow, Caffee, scikit-learn, and Theano.Familiarity and practical experience with programming languages such as R and Python.Familiarity and practical experience in the areas of machine learning, neural networks, statistical learning, and exploratory data analysis.Demonstrated capabilities and knowledge in machine learning and machine intelligence will be a plus.Experience using machine learning technology to work efficiently with datasets such as scripting and Unix/Linux experience will be a plus Regards,Karthik (KP)Resource Development Manager800 E. Campbell Rd, Suite 388Richardson, TX 75081Direct: 972-427-1951Email:  karthik@infovision.com\",\n",
       "  'company': 'InfoVision, Inc.',\n",
       "  'score': 0.5239212941088951},\n",
       " {'jobtitle': 'deep learning data architecture sme start opportunity',\n",
       "  'jobdescription_old': \"Come work for a global marketing technology company providing cutting edge distributive marketing software solutions.  This is a direct hire position located in Boston, MA.  In addition to a highly competitive base salary, this position is bonus and equity eligible.Director, Deep Learning Data ArchitectureYou will be joining a core team who has one purpose: the development and launch of this new suite of software products and tools that enable our enterprise clients to turn data into insights and client engagement. The development of these solutions is a critical initiative, backed by significant investment and is highly visible across the organization. We are guided by the belief that people are our greatest asset and are committed to attracting the best talent.In this position, you'll be responsible for providing expertise and hands on leadership in the design and development of a modern big data engine that will serve as the backbone for our new deep learning products. This includes sourcing into a data reservoir, managing complex access controls and encryption methodologies, developing ETL processes, integrating modern end-user software, and streamlining data consumption by data scientists, reporting teams and operational applications. We'll rely on your proven track record in data architecture and data management principles as well as artificial intelligence and deep-learning technologies.Specific responsibilities include:Design and develop highly scalable and optimized data models using modeling software to document and maintain versions to support Data Marts, Cubes, Data Warehouse, and Operational Data Stores (ODS).Perform source system analysis and meet with business leads to create appropriate requirement definition artifacts.Serve as a key voice in selection of technologies, equipment, and vendors.Develop, adapt and map general machine learning algorithms based on requirements of our softwareInvent new models that combine unsupervised and supervised learning with the kind of creativity usually reserved during novel computing paradigm creationDesign and develop data quality rules for Data Warehouse and Data Mart solutions to ensure data integrity levels are met.Research new database and machine learning technologies and recommend solutions in order to meet requirements and long term performance scalability, & storage needsDevelop data standards in terms of nomenclature, storage, design and deployments.Maintain the end-to-end vision of the data flow diagram and develop logical data models into one or more physical data repositoriesDocument logical data integration (ETL) strategies for data flows between disparate source/target systems for structured and unstructured data into common data reservoir and the enterprise information repositoriesDevelop and maintain controls on data quality, interoperability and sources to effectively manage corporate riskTrain, lead, and mentor staff that may include database engineers and DBAs.Design logical and physical database architecture for DEV, Test, Stage and Prod environments._01Qualifications:Deep passion and fundamental understanding of design, algorithms, and data structures in modern and sub-modern machine learning and AI fieldsStrong understanding of the fundamentals of neural networks and all common general algorithmsExtensive experience and accomplishment are recommended but are not an absolute requirement. Master's or PhD, or equivalent knowledge in computer science, electrical engineering or related fields (statistics, applied math, computational neuroscience)10+ years of hands on experience in Data Management/Data Architecture/Application architecture/Data Development.Experience in high availability SaaS commercial software products is a must5+ years of experience working with modern big data systems for data management, data architecture, security and access controlsExperience managing data transformations using machine learning librariesExperience selecting and implementing the database components of a brand new technology stackWide and extensive expertise in data technologies; i.e., data warehousing, ETL, MDM, DQ, BI and analytical tools. Extensive experience in metadata management and data quality processesHands-on experience with dimensional modeling techniques and creation of logical and physical data models (entity relationship modeling, Erwin diagrams, etc.)Advanced analytical thinking and problem solving skillsExperience designing highly scalable production databases in the cloud (AWS/Azure) is preferredExperience with a variety of relational databasesExperience with NoSQL databases like DynamoDB, Azure Table Storage, Azure Blog Storage or Amazon S3.Knowledge of Data Matching, Data Monitoring, Data Enrichment & Data StandardizationAbility to provide in-depth analysis of where gaps in governance and integration capabilities may lieSome knowledge of current frameworks such as TensorFlow, Caffe, etc.Driven and self-motivated with an entrepreneurial spirit and a commitment to excellence in everything they do.Ability to build and maintain positive, multi-year business relationships with peers and customer\",\n",
       "  'company': 'Business Knowledge Services',\n",
       "  'score': 0.2470268177981108},\n",
       " {'jobtitle': 'data engineer',\n",
       "  'jobdescription_old': 'Reports To: Senior Manager, Data Quality & Analytics Description: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill and/or ability required for this position. Reasonable accommodations may be made, upon request, to enable individuals with disabilities, who otherwise meet the qualifications, to perform the essential functions of the position. Job Summary: The Data Engineer manages and coordinates with internal or external parties the collection, compilation, normalization, and standard analysis of clinical and administrative data assets across diverse projects and data platforms. This position, with sufficient on-site training, will serve as a health systems and clinical data subject matter expert, and the incumbent collaborates with business owners or external clients to establish an analysis plan to answer key business questions and delivers both reporting results and insights in support of RIQI initiatives. Essential Duties & Responsibilities: Data/Information Integrity Develops and executes plans, policies, and practices that control, protect, deliver, and enhance the value and integrity of RIQI\\'s data and information assets. Responsible for and leads Data Profiling and Data Governance at RIQI. Monitors the quality of RIQI\\'s data and information, reports on results, and identifies and recommends system application changes required to improve the quality of data in all applications. Program Integrity Investigates data quality problems, conducts root-cause analysis, corrects errors, and develops process improvement plans across all programs. Integrates data from multiple sources and designs, develops, and generates ad hoc and operational reports in support of objectives. In partnership with program managers, works with business partners on data anomalies and requests for information. Standard Analytics Engages in running and executing standard, recurring reports and ad-hoc analytics. Manipulates and analyzes complex data from varying sources and recommends ways to apply the data. Develops new innovations in the use of the data and data mining techniques to effectively extract meaningful information from data sets. Visualization Presents and communicates complex analytical data and results to varying audiences with a keen understanding of the needs of the audience. Implements end-user training and ongoing support, as well as supporting the development process by providing an interface between business stakeholders. Performs other project duties as assigned. General Requirements: Performs quality work within deadlines with or without direct supervision. Ability to work in a fast-paced dynamic environment and handle multiple tasks. Establishes and maintains effective working relationships. Supports and adheres to RIQI\\'s core values and corporate culture. Represents RIQI in a positive manner to all stakeholders. Performs as a team player. Self-starter; energetic; \"can-do\" attitude. \"Metrics\" mindset. Minimum Qualifications: Education and Experiences B.S. in a quantitative field (Computer Science, Mathematics, Statistics) with 3-5 years\\' work experience. Above average level skills with data management languages (preferably SQL and/or Python, PHP, Javascript) and tools (e.g. knowledgeable of IBI/Information Builders). Novice or Intermediate skills in other data management languages: Python, R, Matlab, SPSS, SAS. Strong commitment to using healthcare clinical and administrative data to deliver insights to healthcare leaders in support of the Institute for Healthcare\\'s \"Triple Aim\" of better care for individuals, better health for populations and lower per capita costs. Desired Qualifications: M.S. or Ph.D. in a quantitative field such as Data Science, Statistics, Epidemiology or Mathematics, or equivalent work experience required. Five to ten years+ experience performing data analysis, with at least three years working with Electronic Medical Record (EMR) and multi-payer claims data. In-depth knowledge of advanced statistical concepts, models, and data analysis. Experience with standard healthcare metrics of quality and utilization, data mining techniques, risk adjustment, predictive modeling. Deep understanding of the healthcare delivery and financing systems. Strong commitment to delivering high level customer service through a collaborative approach to understanding and solving business problems using appropriate data and analytics. Strong written and verbal communication skills and ability to interpret and present complex data and analytic issues to audiences with limited understanding of the topics in a clear, accurate, and relatable manner. Strength with pattern recognition and ability to \"connect the dots\" between unrelated topics. High levels of creativity and quick solving capabilities. Experience solving analytical problems using quantitative approaches. Comfortable working with data and resolving ambiguous issues. Strong organizational and time management skills. Working knowledge of continuous improvement process, methods, and tools. Rhode Island Quality Institute is an EEO/AA Employer. &nbsp &nbsp For more information, or to apply now, you must go to the website below. Please DO NOT email your resume to us as we only accept applications through our website.&nbsp &nbsp https://www.applicantpro.com/j/490773-145047',\n",
       "  'company': 'Rhode Island Quality Institute',\n",
       "  'score': 0.22054321409427208}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendation_search(['machine learning'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Recommendation by profile**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict DevType:\n",
    "- ~~BERT: Consider more columns than skills + groupby(DevType)~~ : to many type have the same skills\n",
    "\n",
    "Work on job:\n",
    "- Extract skills\n",
    "- KNN on job\n",
    "- ~~BERT on skills~~ : to many jobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>employmenttype_jobstatus</th>\n",
       "      <th>jobdescription</th>\n",
       "      <th>joblocation_address</th>\n",
       "      <th>jobtitle</th>\n",
       "      <th>postdate</th>\n",
       "      <th>shift</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Digital Intelligence Systems, LLC</td>\n",
       "      <td>C2H Corp-To-Corp, C2H Independent, C2H W2, 3 M...</td>\n",
       "      <td>Looking for Selenium engineers...must have sol...</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>AUTOMATION TEST ENGINEER</td>\n",
       "      <td>1 hour ago</td>\n",
       "      <td>Telecommuting not available|Travel not required</td>\n",
       "      <td>SEE BELOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University of Chicago/IT Services</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>The University of Chicago has a rapidly growin...</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Information Security Engineer</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>Telecommuting not available|Travel not required</td>\n",
       "      <td>linux/unix, network monitoring, incident respo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Galaxy Systems, Inc.</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>GalaxE.SolutionsEvery day, our solutions affec...</td>\n",
       "      <td>Schaumburg, IL</td>\n",
       "      <td>Business Solutions Architect</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>Telecommuting not available|Travel not required</td>\n",
       "      <td>Enterprise Solutions Architecture, business in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TransTech LLC</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Java DeveloperFull-time/direct-hireBolingbrook...</td>\n",
       "      <td>Bolingbrook, IL</td>\n",
       "      <td>Java Developer (mid level)- FT- GREAT culture,...</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>Telecommuting not available|Travel not required</td>\n",
       "      <td>Please see job description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matrix Resources</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Midtown based high tech firm has an immediate ...</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>48 minutes ago</td>\n",
       "      <td>Telecommuting not available|Travel not required</td>\n",
       "      <td>Configuration Management, Developer, Linux, Ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             company  \\\n",
       "0  Digital Intelligence Systems, LLC   \n",
       "1  University of Chicago/IT Services   \n",
       "2               Galaxy Systems, Inc.   \n",
       "3                      TransTech LLC   \n",
       "4                   Matrix Resources   \n",
       "\n",
       "                            employmenttype_jobstatus  \\\n",
       "0  C2H Corp-To-Corp, C2H Independent, C2H W2, 3 M...   \n",
       "1                                          Full Time   \n",
       "2                                          Full Time   \n",
       "3                                          Full Time   \n",
       "4                                          Full Time   \n",
       "\n",
       "                                      jobdescription joblocation_address  \\\n",
       "0  Looking for Selenium engineers...must have sol...         Atlanta, GA   \n",
       "1  The University of Chicago has a rapidly growin...         Chicago, IL   \n",
       "2  GalaxE.SolutionsEvery day, our solutions affec...      Schaumburg, IL   \n",
       "3  Java DeveloperFull-time/direct-hireBolingbrook...     Bolingbrook, IL   \n",
       "4  Midtown based high tech firm has an immediate ...         Atlanta, GA   \n",
       "\n",
       "                                            jobtitle        postdate  \\\n",
       "0                           AUTOMATION TEST ENGINEER      1 hour ago   \n",
       "1                      Information Security Engineer      1 week ago   \n",
       "2                       Business Solutions Architect     2 weeks ago   \n",
       "3  Java Developer (mid level)- FT- GREAT culture,...     2 weeks ago   \n",
       "4                                    DevOps Engineer  48 minutes ago   \n",
       "\n",
       "                                             shift  \\\n",
       "0  Telecommuting not available|Travel not required   \n",
       "1  Telecommuting not available|Travel not required   \n",
       "2  Telecommuting not available|Travel not required   \n",
       "3  Telecommuting not available|Travel not required   \n",
       "4  Telecommuting not available|Travel not required   \n",
       "\n",
       "                                              skills  \n",
       "0                                          SEE BELOW  \n",
       "1  linux/unix, network monitoring, incident respo...  \n",
       "2  Enterprise Solutions Architecture, business in...  \n",
       "3                         Please see job description  \n",
       "4  Configuration Management, Developer, Linux, Ma...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_job = pd.read_csv('data\\dice_com-job_us_sample.csv')\n",
    "data_job = pd.read_csv('data\\data_job_clean.csv')\n",
    "data_job.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_job['skills'].fillna('', inplace=True)\n",
    "data_job['skills'] = data_job['skills'].apply(lambda x: txt_cleaning(x))\n",
    "data_job['requirements'] = data_job['jobtitle'].apply(lambda x: x.lower()) + ' ' + data_job['jobdescription'].apply(lambda x: x.lower()) + ' ' + data_job['skills'].apply(lambda x: x.lower())\n",
    "\n",
    "data_job.head()\n",
    "data_job.to_csv('data\\data_job_clean.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKILLS_USER = [\n",
    "    \"Python\",\n",
    "    \"Java\",\n",
    "    \"C++\",\n",
    "    \"JavaScript\",\n",
    "    \"HTML/CSS\",\n",
    "    \"SQL\",\n",
    "    \"Git\",\n",
    "]\n",
    "\n",
    "SKILLS_USER = [' '.join(SKILLS_USER)]\n",
    "\n",
    "SKILLS_JOBS = data_job['requirements']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "skills_tfidf = vectorizer.fit_transform(SKILLS_USER)\n",
    "requirements_tfidf = vectorizer.transform(SKILLS_JOBS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour la compétence 'Python Java C++ JavaScript HTML/CSS SQL Git', les postes recommandés sont : Full Stack PHP Engineer, Full Stack Developer, Full Stack Developer, Sr. iOS Developer, Software Engineer, Full Stack Developer, Angular Mobile IOS Developer, Senior Full Stack Developer, M.E.A.N. Stack Developer, Senior Software Developer\n"
     ]
    }
   ],
   "source": [
    "# Définir le nombre de voisins à considérer\n",
    "k = 10\n",
    "nn_model = NearestNeighbors(n_neighbors=k, metric='cosine')\n",
    "nn_model.fit(requirements_tfidf)\n",
    "\n",
    "# Trouver les postes les plus pertinents pour chaque compétence\n",
    "for skill in SKILLS_USER:\n",
    "    skill_tfidf = vectorizer.transform([skill])\n",
    "    _, indices = nn_model.kneighbors(skill_tfidf)\n",
    "\n",
    "    recommended_jobs = data_job.loc[indices[0], 'jobtitle'].values\n",
    "    print(f\"Pour la compétence '{skill}', les postes recommandés sont : {', '.join(recommended_jobs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation_job(skill, requirements_tfidf):\n",
    "    k = 10\n",
    "    nn_model = NearestNeighbors(n_neighbors=k, metric='cosine')\n",
    "    nn_model.fit(requirements_tfidf)\n",
    "\n",
    "    # Trouver les postes les plus pertinents pour chaque compétence\n",
    "    for skill in SKILLS_USER:\n",
    "        skill_tfidf = vectorizer.transform([skill])\n",
    "        _, indices = nn_model.kneighbors(skill_tfidf)\n",
    "\n",
    "        recommended_jobs = data_job.loc[indices[0], 'jobtitle'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Research**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['company', 'employmenttype_jobstatus', 'jobdescription_old',\n",
       "       'joblocation_address', 'jobtitle_old', 'postdate', 'shift', 'skills',\n",
       "       'jobtitle', 'jobdescription', 'requirements'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_job = pd.read_csv('data/data_job_clean.csv')\n",
    "data_job.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_job = data_job[['company', 'jobdescription_old',\n",
    "       'joblocation_address', 'jobtitle_old', 'postdate',\n",
    "       'jobtitle', 'jobdescription', 'requirements']]\n",
    "\n",
    "data_job = data_job[:len(data_job)-1000]\n",
    "\n",
    "data_job.to_csv('data/data_job_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **BERT on skills**\n",
    "\n",
    "Let's try to build our label column, grouping as much as possible jobs together by their title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data_job.copy()\n",
    "temp['jobtitle'] = temp['jobtitle'].apply(lambda x: x.lower().strip())\n",
    "nb_job = len(temp['jobtitle'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15236,  8484,  5381, 21497,  2483,  3912,  9879, 11127, 11447,\n",
       "        1771, 20440, 16035, 13393, 12905, 15059, 19279, 17690,  6444,\n",
       "       17546,   299,  8849, 17022, 15650, 10192], dtype=int64)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Prétraitement des données\n",
    "stop_words = stopwords.words('english')  # Utilisez la liste directement, pas un ensemble\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "tfidf_matrix = vectorizer.fit_transform(temp['jobtitle'].fillna(''))\n",
    "\n",
    "# Calculer la similarité du cosinus\n",
    "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Définir un seuil de similarité\n",
    "threshold = 1  # Vous pouvez ajuster ce seuil en fonction de vos besoins\n",
    "\n",
    "threshold = 0.8\n",
    "similar_indices = cosine_similarities[0].argsort()[::-1][cosine_similarities[0][cosine_similarities[0].argsort()[::-1]] > threshold][1:]\n",
    "\n",
    "similar_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22000it [00:55, 397.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# Regrouper les jobtitles similaires\n",
    "met = []\n",
    "for i, row in tqdm(temp.iterrows()):\n",
    "    # # If we already met this title\n",
    "    # if i in met:\n",
    "    #     continue\n",
    "\n",
    "    # Keep the index with similarity > treshold except the first one that is the current index\n",
    "    similar_indices = cosine_similarities[i].argsort()[::-1][cosine_similarities[i][cosine_similarities[i].argsort()[::-1]] > threshold][1:] \n",
    "    similar_indices = [idx for idx in similar_indices if idx not in met]\n",
    "\n",
    "    # # Store index already met\n",
    "    # met.append(i)\n",
    "    # met = met + list(similar_indices)\n",
    "\n",
    "    # Update title \n",
    "    for idx in similar_indices:\n",
    "        temp.loc[idx, 'jobtitle'] = temp.loc[i, 'jobtitle']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb jobs before cleaning: 14928\n",
      "Nb jobs after cleaning: 9985\n"
     ]
    }
   ],
   "source": [
    "temp2 = temp.copy()\n",
    "temp2['jobtitle'] = temp2['jobtitle'].apply(lambda x: x.lower().strip())\n",
    "nb_job_after_clean = len(temp2['jobtitle'].unique())\n",
    "\n",
    "print(f'Nb jobs before cleaning: {nb_job}\\nNb jobs after cleaning: {nb_job_after_clean}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **BERT on profile**\n",
    "\n",
    "Let's try to groupby the DevType to see if we can have specific skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Respondent</th>\n",
       "      <th>Hobby</th>\n",
       "      <th>OpenSource</th>\n",
       "      <th>Country</th>\n",
       "      <th>Student</th>\n",
       "      <th>Employment</th>\n",
       "      <th>FormalEducation</th>\n",
       "      <th>UndergradMajor</th>\n",
       "      <th>CompanySize</th>\n",
       "      <th>DevType</th>\n",
       "      <th>...</th>\n",
       "      <th>Exercise</th>\n",
       "      <th>Gender</th>\n",
       "      <th>SexualOrientation</th>\n",
       "      <th>EducationParents</th>\n",
       "      <th>RaceEthnicity</th>\n",
       "      <th>Age</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>MilitaryUS</th>\n",
       "      <th>SurveyTooLong</th>\n",
       "      <th>SurveyEasy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed part-time</td>\n",
       "      <td>Bachelor’s degree (BA, BS, B.Eng., etc.)</td>\n",
       "      <td>Mathematics or statistics</td>\n",
       "      <td>20 to 99 employees</td>\n",
       "      <td>Full-stack developer</td>\n",
       "      <td>...</td>\n",
       "      <td>3 - 4 times per week</td>\n",
       "      <td>Male</td>\n",
       "      <td>Straight or heterosexual</td>\n",
       "      <td>Bachelor’s degree (BA, BS, B.Eng., etc.)</td>\n",
       "      <td>Black or of African descent</td>\n",
       "      <td>25 - 34 years old</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The survey was an appropriate length</td>\n",
       "      <td>Very easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed full-time</td>\n",
       "      <td>Bachelor’s degree (BA, BS, B.Eng., etc.)</td>\n",
       "      <td>A natural science (ex. biology, chemistry, phy...</td>\n",
       "      <td>10,000 or more employees</td>\n",
       "      <td>Database administrator;DevOps specialist;Full-...</td>\n",
       "      <td>...</td>\n",
       "      <td>Daily or almost every day</td>\n",
       "      <td>Male</td>\n",
       "      <td>Straight or heterosexual</td>\n",
       "      <td>Bachelor’s degree (BA, BS, B.Eng., etc.)</td>\n",
       "      <td>White or of European descent</td>\n",
       "      <td>35 - 44 years old</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The survey was an appropriate length</td>\n",
       "      <td>Somewhat easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>United States</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed full-time</td>\n",
       "      <td>Associate degree</td>\n",
       "      <td>Computer science, computer engineering, or sof...</td>\n",
       "      <td>20 to 99 employees</td>\n",
       "      <td>Engineering manager;Full-stack developer</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>United States</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed full-time</td>\n",
       "      <td>Bachelor’s degree (BA, BS, B.Eng., etc.)</td>\n",
       "      <td>Computer science, computer engineering, or sof...</td>\n",
       "      <td>100 to 499 employees</td>\n",
       "      <td>Full-stack developer</td>\n",
       "      <td>...</td>\n",
       "      <td>I don't typically exercise</td>\n",
       "      <td>Male</td>\n",
       "      <td>Straight or heterosexual</td>\n",
       "      <td>Some college/university study without earning ...</td>\n",
       "      <td>White or of European descent</td>\n",
       "      <td>35 - 44 years old</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>The survey was an appropriate length</td>\n",
       "      <td>Somewhat easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Yes, part-time</td>\n",
       "      <td>Employed full-time</td>\n",
       "      <td>Some college/university study without earning ...</td>\n",
       "      <td>Computer science, computer engineering, or sof...</td>\n",
       "      <td>10,000 or more employees</td>\n",
       "      <td>Data or business analyst;Desktop or enterprise...</td>\n",
       "      <td>...</td>\n",
       "      <td>3 - 4 times per week</td>\n",
       "      <td>Male</td>\n",
       "      <td>Straight or heterosexual</td>\n",
       "      <td>Some college/university study without earning ...</td>\n",
       "      <td>White or of European descent</td>\n",
       "      <td>18 - 24 years old</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The survey was an appropriate length</td>\n",
       "      <td>Somewhat easy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Respondent Hobby OpenSource         Country         Student  \\\n",
       "0           1   Yes         No           Kenya              No   \n",
       "1           3   Yes        Yes  United Kingdom              No   \n",
       "2           4   Yes        Yes   United States              No   \n",
       "3           5    No         No   United States              No   \n",
       "4           7   Yes         No    South Africa  Yes, part-time   \n",
       "\n",
       "           Employment                                    FormalEducation  \\\n",
       "0  Employed part-time           Bachelor’s degree (BA, BS, B.Eng., etc.)   \n",
       "1  Employed full-time           Bachelor’s degree (BA, BS, B.Eng., etc.)   \n",
       "2  Employed full-time                                   Associate degree   \n",
       "3  Employed full-time           Bachelor’s degree (BA, BS, B.Eng., etc.)   \n",
       "4  Employed full-time  Some college/university study without earning ...   \n",
       "\n",
       "                                      UndergradMajor  \\\n",
       "0                          Mathematics or statistics   \n",
       "1  A natural science (ex. biology, chemistry, phy...   \n",
       "2  Computer science, computer engineering, or sof...   \n",
       "3  Computer science, computer engineering, or sof...   \n",
       "4  Computer science, computer engineering, or sof...   \n",
       "\n",
       "                CompanySize  \\\n",
       "0        20 to 99 employees   \n",
       "1  10,000 or more employees   \n",
       "2        20 to 99 employees   \n",
       "3      100 to 499 employees   \n",
       "4  10,000 or more employees   \n",
       "\n",
       "                                             DevType  ...  \\\n",
       "0                               Full-stack developer  ...   \n",
       "1  Database administrator;DevOps specialist;Full-...  ...   \n",
       "2           Engineering manager;Full-stack developer  ...   \n",
       "3                               Full-stack developer  ...   \n",
       "4  Data or business analyst;Desktop or enterprise...  ...   \n",
       "\n",
       "                     Exercise Gender         SexualOrientation  \\\n",
       "0        3 - 4 times per week   Male  Straight or heterosexual   \n",
       "1   Daily or almost every day   Male  Straight or heterosexual   \n",
       "2                         NaN    NaN                       NaN   \n",
       "3  I don't typically exercise   Male  Straight or heterosexual   \n",
       "4        3 - 4 times per week   Male  Straight or heterosexual   \n",
       "\n",
       "                                    EducationParents  \\\n",
       "0           Bachelor’s degree (BA, BS, B.Eng., etc.)   \n",
       "1           Bachelor’s degree (BA, BS, B.Eng., etc.)   \n",
       "2                                                NaN   \n",
       "3  Some college/university study without earning ...   \n",
       "4  Some college/university study without earning ...   \n",
       "\n",
       "                  RaceEthnicity                Age Dependents  MilitaryUS  \\\n",
       "0   Black or of African descent  25 - 34 years old        Yes         NaN   \n",
       "1  White or of European descent  35 - 44 years old        Yes         NaN   \n",
       "2                           NaN                NaN        NaN         NaN   \n",
       "3  White or of European descent  35 - 44 years old         No          No   \n",
       "4  White or of European descent  18 - 24 years old        Yes         NaN   \n",
       "\n",
       "                          SurveyTooLong     SurveyEasy  \n",
       "0  The survey was an appropriate length      Very easy  \n",
       "1  The survey was an appropriate length  Somewhat easy  \n",
       "2                                   NaN            NaN  \n",
       "3  The survey was an appropriate length  Somewhat easy  \n",
       "4  The survey was an appropriate length  Somewhat easy  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_user = pd.read_csv('data\\survey_results_public.csv')\n",
    "data_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DevType</th>\n",
       "      <th>Respondent</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>[350, 357, 898, 1280, 1350, 1581, 1939, 2193, ...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Server, Amazon, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Back-end developer</td>\n",
       "      <td>[34, 46, 50, 53, 63, 71, 79, 91, 95, 105, 111,...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Server, Amazon, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C-suite executive (CEO, CTO, etc.)</td>\n",
       "      <td>[37, 245, 536, 662, 667, 928, 1095, 1239, 1796...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Server, Amazon, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data or business analyst</td>\n",
       "      <td>[9, 38, 54, 419, 448, 484, 565, 569, 596, 730,...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Amazon, Server, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data scientist or machine learning specialist</td>\n",
       "      <td>[55, 142, 236, 323, 403, 420, 438, 445, 513, 5...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Server, Amazon, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Database administrator</td>\n",
       "      <td>[3, 39, 56, 59, 72, 124, 135, 219, 247, 263, 3...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Server, Amazon, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Designer</td>\n",
       "      <td>[29, 75, 112, 122, 146, 163, 264, 315, 468, 50...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Server, Amazon, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Desktop or enterprise applications developer</td>\n",
       "      <td>[10, 66, 76, 168, 187, 196, 213, 279, 371, 387...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Server, Amazon, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DevOps specialist</td>\n",
       "      <td>[41, 81, 125, 214, 237, 304, 361, 400, 469, 57...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Server, Amazon, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Educator or academic researcher</td>\n",
       "      <td>[164, 240, 708, 1079, 1146, 1227, 1309, 1344, ...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Server, Amazon, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Embedded applications or devices developer</td>\n",
       "      <td>[151, 169, 188, 198, 299, 343, 351, 364, 412, ...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Server, Amazon, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Engineering manager</td>\n",
       "      <td>[43, 103, 302, 345, 663, 709, 720, 751, 902, 9...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Server, Amazon, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Front-end developer</td>\n",
       "      <td>[20, 51, 77, 89, 96, 113, 126, 148, 153, 157, ...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Server, Amazon, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Full-stack developer</td>\n",
       "      <td>[1, 5, 8, 21, 27, 44, 47, 60, 83, 90, 92, 107,...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Server, Amazon, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Game or graphics developer</td>\n",
       "      <td>[11, 175, 254, 642, 738, 991, 1133, 1613, 1825...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Amazon, Server, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Marketing or sales professional</td>\n",
       "      <td>[233, 1020, 1568, 1582, 1677, 1898, 2236, 2765...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Server, Amazon, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Mobile developer</td>\n",
       "      <td>[61, 87, 119, 129, 177, 278, 307, 318, 319, 34...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Server, Amazon, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Product manager</td>\n",
       "      <td>[141, 282, 422, 464, 472, 672, 932, 1202, 1385...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Server, Amazon, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>QA or test developer</td>\n",
       "      <td>[33, 67, 217, 242, 260, 344, 363, 379, 416, 43...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Server, Amazon, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Student</td>\n",
       "      <td>[52, 206, 226, 255, 327, 444, 474, 562, 592, 6...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Server, Amazon, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>System administrator</td>\n",
       "      <td>[7, 85, 194, 228, 270, 338, 466, 488, 584, 645...</td>\n",
       "      <td>{Cobol, TextMate, Go, Atom, Server, Amazon, Ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          DevType  \\\n",
       "0                                                   \n",
       "1                              Back-end developer   \n",
       "2              C-suite executive (CEO, CTO, etc.)   \n",
       "3                        Data or business analyst   \n",
       "4   Data scientist or machine learning specialist   \n",
       "5                          Database administrator   \n",
       "6                                        Designer   \n",
       "7    Desktop or enterprise applications developer   \n",
       "8                               DevOps specialist   \n",
       "9                 Educator or academic researcher   \n",
       "10     Embedded applications or devices developer   \n",
       "11                            Engineering manager   \n",
       "12                            Front-end developer   \n",
       "13                           Full-stack developer   \n",
       "14                     Game or graphics developer   \n",
       "15                Marketing or sales professional   \n",
       "16                               Mobile developer   \n",
       "17                                Product manager   \n",
       "18                           QA or test developer   \n",
       "19                                        Student   \n",
       "20                           System administrator   \n",
       "\n",
       "                                           Respondent  \\\n",
       "0   [350, 357, 898, 1280, 1350, 1581, 1939, 2193, ...   \n",
       "1   [34, 46, 50, 53, 63, 71, 79, 91, 95, 105, 111,...   \n",
       "2   [37, 245, 536, 662, 667, 928, 1095, 1239, 1796...   \n",
       "3   [9, 38, 54, 419, 448, 484, 565, 569, 596, 730,...   \n",
       "4   [55, 142, 236, 323, 403, 420, 438, 445, 513, 5...   \n",
       "5   [3, 39, 56, 59, 72, 124, 135, 219, 247, 263, 3...   \n",
       "6   [29, 75, 112, 122, 146, 163, 264, 315, 468, 50...   \n",
       "7   [10, 66, 76, 168, 187, 196, 213, 279, 371, 387...   \n",
       "8   [41, 81, 125, 214, 237, 304, 361, 400, 469, 57...   \n",
       "9   [164, 240, 708, 1079, 1146, 1227, 1309, 1344, ...   \n",
       "10  [151, 169, 188, 198, 299, 343, 351, 364, 412, ...   \n",
       "11  [43, 103, 302, 345, 663, 709, 720, 751, 902, 9...   \n",
       "12  [20, 51, 77, 89, 96, 113, 126, 148, 153, 157, ...   \n",
       "13  [1, 5, 8, 21, 27, 44, 47, 60, 83, 90, 92, 107,...   \n",
       "14  [11, 175, 254, 642, 738, 991, 1133, 1613, 1825...   \n",
       "15  [233, 1020, 1568, 1582, 1677, 1898, 2236, 2765...   \n",
       "16  [61, 87, 119, 129, 177, 278, 307, 318, 319, 34...   \n",
       "17  [141, 282, 422, 464, 472, 672, 932, 1202, 1385...   \n",
       "18  [33, 67, 217, 242, 260, 344, 363, 379, 416, 43...   \n",
       "19  [52, 206, 226, 255, 327, 444, 474, 562, 592, 6...   \n",
       "20  [7, 85, 194, 228, 270, 338, 466, 488, 584, 645...   \n",
       "\n",
       "                                               skills  \n",
       "0   {Cobol, TextMate, Go, Atom, Server, Amazon, Ma...  \n",
       "1   {Cobol, TextMate, Go, Atom, Server, Amazon, Ma...  \n",
       "2   {Cobol, TextMate, Go, Atom, Server, Amazon, Ma...  \n",
       "3   {Cobol, TextMate, Go, Atom, Amazon, Server, Ma...  \n",
       "4   {Cobol, TextMate, Go, Atom, Server, Amazon, Ma...  \n",
       "5   {Cobol, TextMate, Go, Atom, Server, Amazon, Ma...  \n",
       "6   {Cobol, TextMate, Go, Atom, Server, Amazon, Ma...  \n",
       "7   {Cobol, TextMate, Go, Atom, Server, Amazon, Ma...  \n",
       "8   {Cobol, TextMate, Go, Atom, Server, Amazon, Ma...  \n",
       "9   {Cobol, TextMate, Go, Atom, Server, Amazon, Ma...  \n",
       "10  {Cobol, TextMate, Go, Atom, Server, Amazon, Ma...  \n",
       "11  {Cobol, TextMate, Go, Atom, Server, Amazon, Ma...  \n",
       "12  {Cobol, TextMate, Go, Atom, Server, Amazon, Ma...  \n",
       "13  {Cobol, TextMate, Go, Atom, Server, Amazon, Ma...  \n",
       "14  {Cobol, TextMate, Go, Atom, Amazon, Server, Ma...  \n",
       "15  {Cobol, TextMate, Go, Atom, Server, Amazon, Ma...  \n",
       "16  {Cobol, TextMate, Go, Atom, Server, Amazon, Ma...  \n",
       "17  {Cobol, TextMate, Go, Atom, Server, Amazon, Ma...  \n",
       "18  {Cobol, TextMate, Go, Atom, Server, Amazon, Ma...  \n",
       "19  {Cobol, TextMate, Go, Atom, Server, Amazon, Ma...  \n",
       "20  {Cobol, TextMate, Go, Atom, Server, Amazon, Ma...  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns that are about skills\n",
    "skills_col = ['LanguageWorkedWith','DatabaseWorkedWith',\n",
    "              'PlatformWorkedWith','FrameworkWorkedWith',\n",
    "              'IDE','OperatingSystem']\n",
    "\n",
    "# Keep relevant columns\n",
    "data_user_skills = data_user[['Respondent', 'DevType'] + skills_col]\n",
    "\n",
    "# Fill nan to '' to not disturb the union\n",
    "data_user_skills.fillna('', inplace=True)\n",
    "\n",
    "# Skills union\n",
    "data_user_skills['skills'] = (data_user_skills['LanguageWorkedWith'].apply(lambda x: ' '.join(x.split(';')) + ' ') + \n",
    "                              data_user_skills['DatabaseWorkedWith'].apply(lambda x: ' '.join(x.split(';')) + ' ') + \n",
    "                              data_user_skills['PlatformWorkedWith'].apply(lambda x: ' '.join(x.split(';')) + ' ') + \n",
    "                              data_user_skills['FrameworkWorkedWith'].apply(lambda x: ' '.join(x.split(';')) + ' ') + \n",
    "                              data_user_skills['IDE'].apply(lambda x: ' '.join(x.split(';')) + ' ') + \n",
    "                              data_user_skills['OperatingSystem'].apply(lambda x: ' '.join(x.split(';')))).str.strip()\n",
    "\n",
    "# Drop additionnal skills between parenthesis\n",
    "data_user_skills['skills'] = data_user_skills['skills'].apply(lambda x: re.sub(r'\\([^)]*\\)', '', x))\n",
    "\n",
    "# Drop empty skills row\n",
    "data_user_skills = data_user_skills[~(data_user_skills['skills'] == '')]\n",
    "\n",
    "# Drop duplicates in skills\n",
    "data_user_skills['skills'] = data_user_skills['skills'].apply(lambda x: set(x.split()))\n",
    "\n",
    "# Keep relevant columns\n",
    "data_user_skills = data_user_skills[['Respondent', 'DevType', 'skills']]\n",
    "\n",
    "# Explode DevType to groupby after\n",
    "data_user_skills['DevType'] = data_user_skills['DevType'].str.split(';')\n",
    "data_user_skills['DevType'] = data_user_skills['DevType'].explode('DevType').reset_index(drop=True)\n",
    "\n",
    "grouped_data = data_user_skills.groupby('DevType').agg({\n",
    "    'Respondent': list,\n",
    "    'skills': lambda x: set.union(*x)\n",
    "    }).reset_index()\n",
    "\n",
    "grouped_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Full-stack developer' 'Database administrator' 'DevOps specialist'\n",
      " 'System administrator' 'Engineering manager' 'Data or business analyst'\n",
      " 'Desktop or enterprise applications developer'\n",
      " 'Game or graphics developer' 'QA or test developer' 'Student'\n",
      " 'Back-end developer' 'Front-end developer' 'Designer'\n",
      " 'C-suite executive (CEO, CTO, etc.)' 'Mobile developer'\n",
      " 'Data scientist or machine learning specialist'\n",
      " 'Marketing or sales professional' 'Product manager'\n",
      " 'Embedded applications or devices developer'\n",
      " 'Educator or academic researcher']\n"
     ]
    }
   ],
   "source": [
    "def get_job_from_user():\n",
    "    return data_user['DevType'].dropna().str.split(';').explode('DevType').reset_index(drop=True).unique()\n",
    "\n",
    "print(get_job_from_user())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
